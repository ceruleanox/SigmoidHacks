<html>
    <head>
        <title>SigmoidHacks - Pulse.IT</title>

        <link rel="stylesheet" href="css/styles.css">
        <link rel="preconnect" href="https://fonts.gstatic.com">
        <link href="https://fonts.googleapis.com/css2?family=Kaushan+Script&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@200;400;600&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
    
        <script src="https://cdn.jsdelivr.net/gh/cferdinandi/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>
        
    </head>
    <body>

        <section id="learn-top">
            <img src="img/logo-dark.png" class="logo">
        </section>


        <header>
            <h1>A Video Heart Rate Monitor
                <span>Powered by OpenCV</span>
            </h1>

            <p>Using face detection, ROI extraction, and analyzing RGB fluctuations to sense pulse rate remotely</p>
        </header>
        <div class="learn-intro-container">
            <div class="learn-intro-box box-teal box-push">
                <h2>Neural Networks</h2>
                <p>Laying the foundation for how they work</p>
                <i class="fa fa-connectdevelop fa-3x" aria-hidden="true"></i>
                <a href="#learn-nn-intro">Jump to section</a>
            </div>
            <div class="learn-intro-box box-red">
                <h2>Photoplethysmography</h2>
                <p>Explaining what it is, its uses and benefits</p>
                <i class="fa fa-heartbeat fa-3x" aria-hidden="true"></i>
                <a href="#learn-ppg-intro">Jump to section</a>
            </div>
            <div class="learn-intro-box box-orange box-push">
                <h2>Computer Vision Problems and Methods</h2>
                <p>Delving into face detection, ROI extraction, analyzing RGB fluctuations</p>
                <i class="fa fa-video-camera fa-3x" aria-hidden="true"></i>
                <a href="#learn-cv-intro">Jump to section</a>
            </div>
            <div class="learn-intro-box box-blue">
                <h2>Future Innovations</h2>
                <p>If we can do this, imagine what else we can do!</p>
                <i class="fa fa-bullseye fa-3x" aria-hidden="true"></i>
                <a href="#learn-fi-intro">Jump to section</a>
            </div>
        </div>

        <div id="sideNav">
            <nav>
                <ul>
                    <li><a href="#hero">HOME</a></li>
                    <li><a href="learn.html">LEARN</a></li>
                    <li><a href="https://pulse.w3.ie/">VIEW WEB APP</a></li>
                    <li><a href="#">WATCH DEMO</a></li>
                    <li><a href="https://github.com/Greg-Tarr/Pulse">TRY ON GITHUB</a></li>
                </ul>
            </nav>
        </div>
        <div id="menu-btn">
            <img src="img/menu.png" id="menu">
        </div>

        <div class="pimg-ppg">
            <div class="pimg-text">
                <span class="border">
                    Photoplethysmography
                </span>
            </div>
        </div>

        <!-- LEARN section -->

        <section id="learn-ppg-intro">
            <div class="title-text">
                <h3>INTRODUCTION</h3>
                <h1>What is Photoplethysmography?</h1>
                <br><br>
                <ul>The word itself is derived from the following Greek words:</ul><br>
                <ul>
                    <li>"phōs" - light, to shine</li>
                    <li>"plethysmos" - increasing, enlarging, becoming full</li>
                    <li>"graphein" -to write</li>
                </ul>

                <div class="blobs-container">
                    <div class="blob red" style="animation-delay: 0s"></div>
                    <div class="blob red" style="animation-delay: .1s"></div>
                    <div class="blob red" style="animation-delay: .2s"></div>
                    <div class="blob red" style="animation-delay: .3s"></div>
                    <div class="blob red" style="animation-delay: .4s"></div>
                    <div class="blob red" style="animation-delay: .5s"></div>
                    <div class="blob red" style="animation-delay: .6s"></div>
                    <div class="blob red" style="animation-delay: .7s"></div>
                    <div class="blob red" style="animation-delay: .8s"></div>
                </div>
            </div>
            
            <p>Loosely interpreted, the word refers to the recording of swellings as shown in the light. In this context, the swellings come from blood being pumped from the heart to every part of the body through a system of blood vessels called the circulatory system.

            <p>Every time a person's heart beats, the amount of blood that reaches the capillaries in the fingers and face swells and then recedes. Because blood absorbs light, apps on a phone can measure heart rate by detecting ebb and flow just by using the flash of a camera phone to illuminate the skin and create a reflection.</p>

            <p>As a caveat, it shouldn't come as a surprise that DIY heart rate tracking apps don't perform as consistently as nor as well as clinical grade equipment (e.g. electrocardiogram) and known methods (e.g. fingertip pulse oximetry). Studies have found that heart rate readings generated by apps were off by 20+ beats per minute in over 20% of measurements. At the same time, if you're just looking for a high-level overview of your heart rate, it's hard to beat the convenience that this low-cost, non-invasive and safe optical technique provides.</p>

            <p>So much goes on underneath the skin that is hard to see with the naked eye. While it's much easier for computers to do the same, they have their own challenges to overcome, too.</p>

            <p>
                <center><a href="#learn-top">Back to the top</a></center>
            </p>

            
 
        </section>

        <!-- BENEFITS section -->

        <section id="benefits">
            <div class="title-text">
                <h3>Benefits</h3>
                <h1>Why use it?</h1>
                <p class="subtitle">Hover over the images below for more info.</p>
            </div>
            <div class="benefits-box">
                <div class="single-benefit">
                    <img src="img/learn-benefit-1.jpg">
                    <div class="static-overlay"></div>
                    <div class="benefit-title">Low-Cost</div>
                    <div class="overlay"></div>
                    <div class="benefit-desc">
                        <h3>Low-Cost</h3>
                        <hr>
                        <p>It's an optical technique used to detect heartbeat that won't break the piggy bank.</p>
                    </div>
                </div>
                <div class="single-benefit">
                    <img src="img/learn-benefit-2.jpg">
                    <div class="static-overlay"></div>
                    <div class="benefit-title">Non-Invasive</div>
                    <div class="overlay"></div>
                    <div class="benefit-desc">
                        <h3>Non-Invasive</h3>
                        <hr>
                        <p>It makes measurements at the surface of the skin to provide valuable information related to the cardiovascular system.</p>
                    </div>
                </div>
                <div class="single-benefit">
                    <img src="img/learn-benefit-3.jpg">
                    <div class="static-overlay"></div>
                    <div class="benefit-title">Safe</div>
                    <div class="overlay"></div>
                    <div class="benefit-desc">
                        <h3>Safe</h3>
                        <hr>
                        <p>It eliminates the need to surgically implant a device to sense pressure and the risk of infection.</p>
                    </div>
                </div>
                <div class="single-benefit">
                    <img src="img/learn-benefit-4.jpg">
                    <div class="static-overlay"></div>
                    <div class="benefit-title">Simple</div>
                    <div class="overlay"></div>
                    <div class="benefit-desc">
                        <h3>Simple</h3>
                        <hr>
                        <p>All you need is a common webcam or network IP camera on a smartphone!</p>
                    </div>
                </div>
            </div>
            <p>
                <center><a href="#learn-top">Back to the top</a></center>
            </p>
        </section>

        <div class="pimg-nn">
            <div class="pimg-text">
                <span class="border">
                    Neural Networks
                </span>
            </div>
        </div>

        <section id="learn-nn-intro" class="section section-dark">
            <div class="title-text">
                <h3>INTRODUCTION</h3>
                <h1>What is a neural network?</h1>
            
            <p>Neural networks form the base of deep learning, which is a subfield of machine learning where the algorithms are inspired by the structure of the human brain. That is, neural networks are humankind's attempt to copy the brain to create artificial intelligence. Similar to how the brain works, neural networks take in data, train themseles to recognize patterns in data, and then predict the output for a new set of similar data.</p>

            <h1>How does the brain work?</h1>

            <p>Granted the brain is the most complicated organ in the human body that has been studied and hypothesized for centuries, there's a lot we still don't know. For now, here's what we do know.</p>
                
            <p>In the human brain, there is a complex network of 85+ billion neurons that interact with each other to communicate and process information based on what we see, hear, move, think, etc. Each neuron has:</p>
                <ul>
                    <li><b>dendrites</b>, which receives input from other neurons</li>
                    <li><b>axon</b>, which is basically the output of the neuron</li>
                </ul>
            <br><br>

            <p>Mouse over the below image showing a network of brain neurons to explore what a single neuron looks like in outline form.</p>

            <canvas id="canvas-brain-neurons" width="1250" height="640"></canvas>
            <p><center>Mouse over image to reveal more</center></p>
            <br><br>

            <p>Connected to other neurons' axons, dendrites receive neurotransmitters from the axon of other neurons, which in turn creates a small positive spike in the neuron. If the neuron receives enough positive spike, the neuron sends a positive spike down its axon, which then releases neurotransmitters to all neurons connected to its axon branches. This, in turn, produces a positive spike in those neurons — and the cycle goes on and on.</p> 
                
            <p>Of note, some connections between neurons are stronger than others, and neurons with stronger connections receive a larger positive spike than neurons with weaker connections. That means neurons with stronger connections are closer to being triggered to release neurotransmitters to their connected neurons.</p>

            <h1>How does this translate to neural networks?</h1>

            The below image transitions from a simplified outline of what a network of neurons look like to a network graph. 

            <div id="learn-nn-graph-cf">
                <img src="img/learn-nn-neuron-network-graph-weighted.png">
                <img src="img/learn-nn-neuron-network-graph.png">
                <img src="img/learn-nn-neuron-network.png">
            </div>

            <br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>

            <p>In network graph form, the circles are neurons and the lines are connections between neurons. Each connection has a strength associated with it, called the weight. Weight can range between -1 and 1. Weights in red are positive connections, and weights in blue are negative connections.</p>

            <p>In network graph form, the circles are neurons and the lines are connections between neurons. Each connection has a strength associated with it, called the weight, and it ranges between -1 and 1.</p>

            <p>A single neuron or node in the graph is called a perceptron. It has many connections to other perceptrons coming in and going out. Inside it, two processes go on. The first sums up all the connections or inputs coming into the perceptron, and the second is known as the activation function. While there are many activation functions available, for our purposes we'll talk about the step function. </p>
            
            <p>The activation function computes how much input the neuron needs before it gets triggered. Let's put it in math terms whereby the function returns 1 if x is positive, and it returns 0 if x is zero or negative. The perceptron then outputs the result of the activation function to each neuron that it is connected to. These outputs are then multipled by the weights associated with each connection. And that's basically a very simplified version of how the brain works and how a neural network functions behind the scenes.</p>
 
            <h1>So how does this work?</h1>
            
            <p>Ultimately, neural networks simulate behavior. Let's start by laying down some key terminology.</p>

            <p>A <b>layer</b> is a column of neurons. In our example, we have 4 columns. The first layer is known as the input layer, and the final layer is known as the output layer. There's also something called the <b>bias neuron</b>; it's a neuron like the input neuron, but it's always set to 1. This neuron can be connected to any neuron in the input layer. We'll talk more about this later.</p>

            <p>In the context of computer vision, a camera sees a 2x2 image, and pixels can only be black or white. To detect a pattern, we eventually want to see one of two possibilities: either a grid where the upper left quadrant and lower right quadrant are black, or a grid where the lower left quadrant and upper right quadrant are black. Or really, a checkerboard pattern.</p>

            <p>In a neural network, each layer is combining features from the previvous layer. Brandon Rohrer helps explain and visualize the above really well in <a href="https://www.youtube.com/watch?v=ILsA4nyG7I0&lc=UghnCyw_Li-mGHgCoAEC&ab_channel=BrandonRohrer" target="_blank">this video</a>.</p>

            <iframe width="560" height="315" src="https://www.youtube.com/embed/ILsA4nyG7I0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            
            <br><br><br>
            
            <p>When an input doesn't end up in a checkerboard pattern, the output neuron should output 0. Of course, neural networks are a lot more complicated than this, so it's not feasible the manually set all the neurons and weights. This is where the genetic algorithm comes in — to learn and evolve ways and algorithms. Those with better behaviors survive and pass on its genes (i.e. the weights), and through evolution the neural network knows how to do the desired task at hand.</p>
            
            <p>
                <center><a href="#learn-top">Back to the top</a></center>
            </p>        
 
        </section>

        <div class="pimg-cv">
            <div class="pimg-text">
                <span class="border">
                    Computer Vision
                </span>
            </div>
        </div>

        <section id="learn-cv-intro" class="section section-light">
            <div class="title-text">
                <h3>INTRODUCTION</h3>
                <h1>Methodologies</h1>
            
                <h2>Face Detection</h2>
                <br><br>
                <p>Face detection is a way to find and identify human faces in digital images or video. It typically uses a feature invariant method by searching for human eyes, which is one of the easiest features to detect. From there, the algorithm might attempt to detect the mouth, nose, and even the eyes' iris. Once the algorithm concludes that it has found a facial region, it applies additional tests to confirm that it has detected a face.</p>

                <p>There are various methods used in face detection, and each has its own advantages and disadvantages:</p>

                <h4>Knowledge-based or Rule-based</h4>
                <p><center>Describes a face based on rules. The hard part is coming up with well-defined rules!</center></p>

                <h4>Feature invariant methods</h4>
                <p><center>Uses features like a person's eyes, nose, or mouth to detect a face. However, variations in noise and light on the image can affect its accuracy.</center></p>

                <h4>Appearance-based methods</h4>
                <p><center>Uses statistical analysis and machine learning to find relevant characteristics of face images.</center></p>
                
                <p>There are also techniques used in face detection to help identify faces. Removing the background, for example, can help reveal face boundaries for images with a mono-color background. In color images, sometimes skin color can be used to find faces, but it doesn't always work and can <a href="https://www.ajl.org/" target="_blank">do harm</a>. Using motion to find faces by calculating the moving area is yet another technique. The assumption made here is that a face is almost always moving in real-time video. Of course, there's the inherent risk of objects moving in the background. </p>

                <p> Nevertheless, detecting faces can be difficult because of varying factors like pose, expression, position and orientation, presence of glasses or facial hair, and even image resolution.</p>

                <h2>ROI Extraction</h2>
                <br><br>
                <p>According to Wikipedia, a region of interest (ROI), are samples within a data set identified for a particular purpose. It's a form of annotation, often associated with categorical or quantitative information (e.g. volume), expressed as text or in a structured form.</p>
                    
                <p>In the context of computer vision, the ROI defines the borders of an object under consideration. In many applications, symbolic (textual) labels are added to a ROI, to describe its content in a compact way. And within a ROI, there may be individual points of interest (POIs).</p>

                <p>There are three fundamentally different means of encoding a ROI:</p>

                <p>1.) As an integral part of the sample data set, with a unique or masking value that may or may not be outside the normal range of normally occurring values and which tags individual data cells</p>

                <p>2.) As separate, purely graphic information, such as with vector or bitmap (rasterized) drawing elements, potentially with some accompanying plain (unstructured) text in the format of the data itself</p>
                    
                <p>3.) As a separate structured semantic information (e.g. coded value types) with a set of spatial and/or temporal coordinates</p>
                
                <h2>RGB Analysis</h2>
                <br><br>

                <p>From the pixels contained in the region of interest, the raw signal can be computed per frame as the mean value of each of the RGB color channels. In doing so, we can average out camera noise contained in single pixels; this is also known as spatial pooling. After normalizing the level of raw signals, we can then compare whether variations are significant. 
                    
</p>
            <p>
                <center><a href="#learn-top">Back to the top</a></center>
            </p>

        </section>     
        
        <div class="pimg-fi">
            <div class="pimg-text">
                <span class="border">
                    Future Innovations
                </span>
            </div>
        </div>

        <section id="learn-fi-intro" class="section section-dark">
            <div class="title-text">
                <h3>WHAT'S NEXT</h3>
                <h1>Use Cases</h1>
            
                <p>With the rise in telehealth and more sophisticated machine learning possibilities being discovered, there are so many use cases for this — including but not limited to:  </p>

                <h2>Measuring Heart Health </h2>
                <br><br>
                <p>Knowing your heart rate is important because the heart's function is so crucial. Namely, the heart is what's responsible for circulating oxygen and nutrient-rich blood throughout your body. When it's not working as expected, basically everything in the body is affected.</p>

                <h2>Training and Fitness Optimization</h2>
                <br><br>
                <p>Many top athletes and individuals who regularly exercise are interested in optimizing their training and fitness by understanding how their body responds to training and recovers.</p>

                <h2>Improving Meditation</h2>
                <br><br>
                <p>A lower heart rate is one of the positive physiological effects of meditation and can indicate how effect a practice is.</p>

                <h2>Anxiety Treatment</h2>
                <br><br>
                <p>Anxiety disorders are the most common psychiatric disorders today that have been shown to increase the risk of heart disease, so finding a slower heart rate could help with identifying and getting checked out sooner.</p>

            <p>
                <center><a href="#learn-top">Back to the top</a></center>
            </p>

        </section>          
 
 
    </section>

 

    </body>

    <script src="js/menu.js"></script>
    <script src="js/scroll.js"></script>
    <script src="js/xray.js"></script>

</html>
